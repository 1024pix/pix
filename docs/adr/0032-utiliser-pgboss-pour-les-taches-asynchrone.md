# 1. Gestion des tÃ¢ches asynchrones avec PgBoss

Date : 2022-02-24

## Ã‰tat

En cours

## Contexte

L'utilisation des Ã©vÃ¨nements dans l'application a mis en Ã©vidence des problÃ©matiques de cohÃ©rences des donnÃ©es que nous
ne gÃ©rons pas pour le moment. Quand un Ã©vÃ¨nement est lancÃ© aprÃ¨s l'exÃ©cution d'un use case et que l'application plante,
les traitements liÃ©s Ã  la gestion de l'Ã©vÃ¨nement ne sont pas forcÃ©ment exÃ©cutÃ©s.
Par exemple aprÃ¨s le partage des rÃ©sultats d'une participation Ã  une campagne nous utilisons un Ã©vÃ¨nement pour
dÃ©clencher le calcul du snapshot des rÃ©sultats. En cas de problÃ¨me, la participation est partagÃ©e, mais on peut ne
pas avoir de snapshot.

C'est une situation qui s'est produite lorsque Scalingo a fait de la maintenance sur les bases de donnÃ©es.

### Solution : PgBoss

PgBoss est une job queue qui est persistÃ© dans une base PostgreSQL.

![job-states](../assets/job-states.png)

La solution s'oriente vers PgBoss parce que la queue est dans un base PG, tout comme le reste de nos donnÃ©es.
On peut envisager d'ajouter un job en BDD et de faire les traitements d'un use case dans une mÃªme transaction. Ce qui
permet de ne pas perdre le traitement d'un Ã©vÃ¨nement en cas d'erreur. 

#### 1. Les migrations PgBoss

Les migrations PgBoss sont jouÃ©es quand on appelle la fonction [pgBoss.start()](https://github.com/timgit/pg-boss/blob/master/docs/readme.md#start).

Ces migrations peuvent prendre du temps s'il existe beaucoup de jobs dans la BDD. Pour pouvoir jouer ces
migrations sans introduire ce problÃ¨me il faut ajouter au script db:migrate l'appel Ã  la fonction start de PgBoss.

```js
// api/package.json
"db:migrate": "knex --knexfile db/knexfile.js migrate:latest && node scripts/database/run-pg-boss-migration.js",
  
require('dotenv').config();
const PgBoss = require('pg-boss');

async function main() {
  console.log(process.env);
  const databaseUrl = process.env.NODE_ENV === 'test' ? process.env.TEST_DATABASE_URL : process.env.DATABASE_URL;
  const boss = new PgBoss(databaseUrl);
  await boss.start();
  await boss.stop();
}

```

Le but c'est de ne pas avoir Ã  faire le pgBoss.start Ã  chaque fois qu'on lance PgBoss et de prendre le risque que le
start prenne du temps Ã  cause de migrations. Si jamais un start est fait dans un conteneur web on peut bloquer un worker
le temps de faire les migrations PgBoss.

#### 2. Ajouter un job

Dans le conteneur web le contrÃ´leur utilisera les Ã©vÃ¨nements pour crÃ©er des jobs. On doit crÃ©er une classe / service qui
sera instanciÃ© (en prenant la transaction knex en paramÃ¨tre) dans l' EventDispatcher. Ensuite, l'EventDispatcher passera
cette classe / service au handler qui l'utilisera pour ajouter un job.

La classe / service fera une requÃªte en BDD pour ajouter une ligne dans la table `job` du schÃ©ma de PgBoss en spÃ©cifiant
le nom (name), paramÃ¨tres (data) et les informations pour configurer le job.

> ##### Job table
>
> The following command is the definition of the primary job table. For manual job creation, the only required column is name. All other columns are nullable or have sensible defaults.
>
>  ```sql
>  CREATE TABLE ${schema}.job (
>     id uuid primary key not null default gen_random_uuid(),
>     name text not null,
>     priority integer not null default(0),
>     data jsonb,
>     state ${schema}.job_state not null default('${states.created}'),
>     retryLimit integer not null default(0),
>     retryCount integer not null default(0),
>     retryDelay integer not null default(0),
>     retryBackoff boolean not null default false,
>     startAfter timestamp with time zone not null default now(),
>     startedOn timestamp with time zone,
>     singletonKey text,
>     singletonOn timestamp without time zone,
>     expireIn interval not null default interval '15 minutes',
>     createdOn timestamp with time zone not null default now(),
>     completedOn timestamp with time zone,
>     keepUntil timestamp with time zone NOT NULL default now() + interval '14 days',
>     on_complete boolean not null default true,
>     output jsonb
>   )
>```
>
**Pour pouvoir faire Ã§a il faut repasser Ã  l'EventDispatcher la transaction Ã  chaque traitement d'Ã©vÃ¨nement.**

En faisant Ã§a il faut **ABSOLUMENT** que toutes les requÃªtes faites dans le handler passe par la transaction, sinon on
prend le risque d'avoir des deadlocks. C'est Ã  cause de ces problÃ¨mes qu'on a dÃ©cidÃ© de ne plus utiliser les
transactions dans les handler d'Ã©vÃ¨nement. Quand la gestion d'Ã©vÃ¨nement a Ã©tÃ© mise en place on n'a pas assez communiquÃ©
et formÃ© les gens sur ce point.

En fonction des jobs on peut vouloir les lancer plusieurs fois ou pas. Il n'y a pas de garantie qu'un job n'est pas dÃ©jÃ 
Ã©tÃ© exÃ©cutÃ©. Par exemple le job marche, mais le conteneur plante avant que PgBoss mette Ã  jour le job en BDD.
Le job aura Ã©tÃ© exÃ©cutÃ©, mais il n'est pas marquÃ© comme terminÃ©. Dans cette situation PgBoss finira par relancer le job.
Pour chaque job il faut savoir si on peut / doit le rejouer en cas d'Ã©chec.
Par exemple un envoi de mail ne doit pas forcÃ©ment Ãªtre relancÃ©, par opposition il y a peu d'impact si on calcule
plusieurs fois les rÃ©sultats d'un participant Ã  une campagne.

**En fonction du contexte il faut dÃ©terminer si jouer le job plusieurs fois est acceptable.**

ðŸ’¡ Une classe/service par job peut permettre de configurer la file facilement. (Nombre de tentatives par exemple).

ðŸ’¡ Il faudrait des logs pour monitorer l'ajout des jobs dans Datadog. (Avec de l'hÃ©ritage c'est faisable facilement).

##### Exemple non contractuel

```js
class Job {
  constructor(config, queryBuilder, logger) {
    this.name = config.name;
    this.retryLimit = config.retryLimit || 0;
    this.retryDelay = config.retryDelay || 30;
    this.queryBuilder = queryBuilder;
    this.logger = logger;
  }

  async schedule(data) {
    await this.queryBuilder.raw(
      'INSERT INTO pgboss.job (name, data, retryLimit, retryDelay) VALUES (:name, :data, :retryLimit, :retryDelay)',
      {
        name: this.name,
        retryLimit: this.retryLimit,
        retryDelay: this.retryDelay,
        data,
      }
    );
    this.logger.info(`Job ${this.name} scheduled`);
  }
}

class JobRetryEnabled extends Job {
  constructor(queryBuilder, logger) {
    super({ name: 'RetryEnabled', retryLimit: 3 }, queryBuilder, logger);
  }
}

class JobRetryDisabled extends Job {
  constructor(queryBuilder, logger) {
    super({ name: 'RetryDisable' }, queryBuilder, logger);
  }
}
```

#### 3.Lancer un job

Il y aura un conteneur dÃ©diÃ© pour jouer les jobs (dans la mÃªme idÃ©e que celui avec les CRON).

##### JobQueue

Pour ne pas dÃ©pendre trop directement de PgBoss il faut wrapper PgBoss dans une classe ou un service.

###### Exemple non contractuel
```js
const PgBoss = require('pg-boss');

class JobQueue {
  constructor() {
    this.pgBoss = new PgBoss(process.env.DATABASE_URL);
  }

  async performJob(name, handler) {
    await this.pgBoss.start();
    this.pgBoss.work(name, (job) => {
      handler(job.data);
    });
  }

  async stop() {
    await this.pgBoss.stop({ graceful: false, timeout: 1000 });
  }
}
```
On peut ajoutÃ© des tests automatisÃ©s sur le wrapper. C'est des tests qui ont un interÃªt en cas de montÃ©e de version de
PgBoss ou de changement le lib. (Ce n'est pas forcÃ©ment utile de lancer ces tests dans la CI).

###### Exemple non contractuel
```js
beforeEach(async function () {
    await knex('job')
      .withSchema('pgboss')
      .insert({ name: 'job', data: { jobParam: 1 } });
  });

it('executes job when a job is added to the queue', function (done) {
  const handler = (params) => {
    try {
      expect(params).to.deep.equal({ jobParam: 1 });
      done();
    } catch (err) {
      done(err);
    }
  };

  const jobQueue = new JobQueue(knex);

  jobQueue.performJob('job', handler);
});
```

##### JobHandler

Pour les mÃªmes raisons (testabilitÃ©, indÃ©pendance, ...) il est nÃ©cÃ©ssaire de wrapper les jobs dans des classes / services.

###### Exemple non contractuel
Version sans transaction

```js
const DomainTransaction = require('../DomainTransaction');

class JobHandler {
  constructor(name, jobQueue, dependencies = {}) {
    this.name = name;
    this.dependencies = dependencies;
    this.jobQueue = jobQueue;
  }

  async perform() {
    const handler = (params) => this._handle({ ...params, ...this.dependencies });
    await this.jobQueue.performJob(this.name, handler);
  }

  async _handle() {
    throw new Error('NOT IMPLEMENTED');
  }

  async stop() {
    await this.jobQueue.stop({ graceful: false, timeout: 1000 });
  }
}

class JobPocHandler extends JobHandler {
  constructor(jobQueue, logger) {
    super('job', jobQueue);
    this.logger = logger;
  }

  async _handle({ date }) {
    this.logger.info(`Job Trx ${date}: STARTED`);
    setTimeout(() => this.logger.info(`Job ${date}: Sleeping`), 5000);
    await sleep(10000);
    this.logger.info(`Job ${date}: FINISHED`);
  }
}
```

Version avec transaction
```js
class JobTrxHandler extends JobHandler {
  async perform() {
    const handler = async (params) => {
      await DomainTransaction.execute(async (domainTransaction) => {
        await this._handle({ ...params, domainTransaction, ...this.dependencies });
      });
    };
    await this.jobQueue.performJob(this.name, handler);
  }
}

class JobPocTrxHandler extends JobTrxHandler {
  constructor(jobQueue, logger) {
    super('job', jobQueue);
    this.logger = logger;
  }

  async _handle({ domainTransaction }) {
    await domainTransaction
      .knexTransaction('organizations')
      .update({ name: `Orga-PgBoss` })
      .where({ id: 1 });
  }
}
```
**Les tests**
###### Exemple non contractuel
```js
it('update organization name', async function () {
    databaseBuilder.factory.buildOrganization({ id: 1, name: 'Orga' });
    await databaseBuilder.commit();

    const jobQueue = {
      performJob: async function (name, handler) {
        await handler();
      },
    };

    const jobHandler = new JobPocTrxHandler(jobQueue);

    await jobHandler.perform();

    const organization = await knex('organizations').where({ id: 1 }).first();
    expect(organization.name).equal('Orga-PgBoss');
  });
```

Je n'ai pas rÃ©ussi Ã  utiliser une transaction pour l'exÃ©cution du job et la mise Ã  jour du job par PgBoss.
Il y a plusieurs requÃªtes faites par PgBoss :
- RÃ©cupÃ©ration de job.
- Modification du statut job.
- Archivage des jobs.

La lib permet de crÃ©er une transaction Ã  chaque fois, mais c'est complexe d'utiliser une mÃªme transaction pour le job
et la mise Ã  jour du statut du job.

### Conclusion

Ã‡a fonctionne et ce n'est pas trop dur Ã  mettre en place. Il y a quand mÃªme quelques points d'attention.

**Avantage(s):**

- Permet d'avoir une cohÃ©rence entre les traitements d'un use case et l'ajout d'un job en BDD.


- Permet d'avoir une politique de retry gratuitement.


- Permet de gÃ©rer finement le nombre de consommateurs d'une file.

**InconvÃ©nient(s):**

- Utilisation de la mÃªme transaction dans le use case et dans le handler d'Ã©vÃ¨nement. (Pas un vrai problÃ¨me, mais on a
dÃ©jÃ  fait des bÃªtises)


- Pas de garantie qu'un job qui a Ã©chouÃ© n'a pas Ã©tÃ© exÃ©cutÃ©. (Il faut gÃ©rer Ã§a avec de la configuration de file)

## DÃ©cision

Adoption de PgBoss pour la gestion des job asynchrones. PgBoss permet de rajouter un job en bdd dans la mÃªme transaction
que celle d'un use case. Ce qui rÃ©sout notre problÃ©matique de dÃ©part.


## ConsÃ©quences

On utilise PgBoss et on commence une PR avec PgBoss pour le calcul des rÃ©sultats d'une participation.
